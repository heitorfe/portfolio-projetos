<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Portfólio de Projetos</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link id="theme-link" rel="stylesheet" href="assets/css/dark.css">
		<link rel="stylesheet" href="assets/css/carousel.css">

	</head>
	
	
	<body class="is-preload">
		

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Portfólio de projetos</strong> em dados e software</a>
									<ul class="icons">
									</ul>
								</header>

								<!-- languages -->
								<header id="lang" style="display: flex; align-items: center; gap: 10px;">
									<a href="#" class="image"><img src="images/bra.svg" width=50 height=40 alt=""></a>
									<a href="https://heitorfe.github.io/portfolio-projetos/indexEN" class="image"><img src="images/usa.svg" width=50 height=40 alt=""></a>
									<button id="theme-toggle">Toggle Theme</button>
								</header>



								</header>


							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Olá, seja muito bem vindo(a) ao meu portfólio de projetos</h1>
										</header>
										<p>Nessa página você vai conhecer um pouco da minha trajetória e as minhas habilidades em <strong>Ciência, Análise e Engenharia de Dados</strong>,<strong> Inteligência Artificial</strong> e <strong>Infraestrutura na Nuvem</strong>, através de projetos com dados públicos.</p>
									</div>
									<span class="image object">
										<img src="images/pic10.jpg" alt="" />
									</span>
								</section>


								<!-- Sobre mim -->
									<section>
										<header class="major">
											<h1>Sobre mim</h1>
										</header>
											<h2 id="content">Meu nome é Heitor Felix</h2>
											<p>Sou formado em Ciência de Dados pela Uninter e atualmente trabalho como <strong>Engenheiro de Dados</strong> na NTT Data, construindo e otimizando pipelines de dados em <strong>Databricks</strong> para o setor financeiro. Tenho mais de 3 anos de experiência em Engenharia de Dados, com sólida atuação em arquiteturas de Data Lakehouse, desenvolvimento de soluções com IA (RAG/LLMs), e implementação de infraestrutura em nuvem. Possuo certificações Databricks (Associate e Professional) e Azure (DP-203, AZ-900, DP-900). Explore meus projetos abaixo e sinta-se à vontade para entrar em contato.</p>

									</section>

<!-- Skills (loaded from shared/skills.html) -->
<div id="skills-placeholder"></div>

<!-- Certificações (loaded from shared/certifications.html) -->
<div id="certifications-placeholder"></div>

								<!-- Experiência -->
									<section>
										<header class="major">
											<h1>Experiência Profissional</h1>
										</header>
										<div class="project">
											<h2>Engenheiro de Dados na NTT Data</h2>
											<span class="experience-period">2025 - Atual</span>
											<p>Construção e otimização de pipelines de dados em <strong>Databricks</strong> para clientes do setor financeiro. Atuação em projetos de migração para arquiteturas modernas de <strong>Data Lakehouse</strong>, garantindo performance, escalabilidade e governança de dados.</p>
										</div>
										<div class="project">
											<h2>Engenheiro de Dados Pleno na Sapiensia Tecnologia</h2>
											<span class="experience-period">2022 - 2024</span>
											<p>Liderança técnica em projetos de engenharia de dados, desenvolvendo pipelines críticos em <strong>Azure</strong> e <strong>Databricks</strong>. Implementação de soluções de IA com <strong>RAG e LLMs</strong> para automação de processos. Arquitetei estratégias de <strong>disaster recovery</strong> e infraestrutura serverless. Responsável por dashboards analíticos e automações com Python que impactaram diretamente decisões de negócio.</p>
										</div>
										<div class="project">
											<h2>Estágio em Ciência de Dados na 027capital</h2>
											<span class="experience-period">2021 - 2022</span>
											<p>Desenvolvimento de modelos de <strong>previsão de churn</strong> e pipelines de ingestão de dados utilizando <strong>Python</strong> e <strong>Google Cloud</strong>. Criação de software para processamento e análise de dados financeiros.</p>
										</div>
									</section>


							<!-- Section -->
							<section>
								<header class="major">
									<h1>Projetos</h1>
								</header>
								<div class="posts">
							<article class="featured">
								<a href="https://github.com/heitorfe/olist-lakehouse-2.0" class="image"><img
									src="images/olist2.png" alt="Arquitetura Olist Lakehouse 2.0" /></a>
								<h3>Data Lakehouse Avançado: Olist Lakehouse 2.0</h3>
								<div class="tech-tags">
									<span class="tech-tag data-eng">Databricks</span>
									<span class="tech-tag data-eng">Delta Lake</span>
									<span class="tech-tag data-eng">PySpark</span>
								</div>
								<p>Esta é a segunda versão do projeto Olist, agora implementando práticas modernas de
								engenharia de
								dados no <strong>Databricks Lakehouse</strong> com foco em pipelines declarativas,
								governança e
								processamento incremental em escala.
								A arquitetura segue o padrão <strong>Medallion (Bronze, Silver, Gold)</strong>
								utilizando
								<strong>Lakeflow Declarative Pipelines</strong> (ex-Delta Live Tables), com ingestão
								contínua
								via <strong>AutoLoader</strong> e tratamento de mudanças com <strong>AUTO CDC</strong>
								para
								dimensões SCD Type 1 e Type 2.
								O projeto incorpora <strong>Data Quality com expectations</strong> em todas as camadas,
								governança centralizada com <strong>Unity Catalog</strong>, rastreabilidade de dados
								(lineage) e
								separação de pipelines para dados transacionais append-only e entidades com mudanças
								históricas.
								Toda a infraestrutura e pipelines são implantados via <strong>Databricks Asset
									Bundles</strong>,
								com CI/CD automatizado, validação de código, testes e deploy entre ambientes de
								desenvolvimento,
								staging e produção.
								<p>
									<!-- Lists -->
								<div class="row">
									<div class="col-6 col-12-small">
										<h4>Ferramentas utilizadas</h4>
										<ul>
											<li>Databricks Lakehouse & Delta Lake</li>
											<li>Lakeflow Declarative Pipelines (DLT)</li>
											<li>AutoLoader (ingestão incremental)</li>
											<li>AUTO CDC (SCD Type 1 e Type 2)</li>
											<li>Unity Catalog (governança e lineage)</li>
											<li>Databricks Asset Bundles (IaC)</li>
											<li>GitHub Actions (CI/CD)</li>
											<li>SQL, PySpark</li>
										</ul>
										<ul class="actions">
											<li><a href="https://github.com/heitorfe/olist-lakehouse-2.0"
													class="button">Saiba mais</a></li>
										</ul>
									</div>
								</div>
							</article>


									<article>
										<a href="https://github.com/heitorfe/pipeline-deputados" class="image"><img src="images/deputados.png" alt="Diagrama do projeto deputados" /></a>
										<h3>Pipeline de Dados da Câmara dos Deputados</h3>
										<div class="tech-tags">
											<span class="tech-tag data-eng">Snowflake</span>
											<span class="tech-tag data-eng">dbt</span>
											<span class="tech-tag data-eng">Airflow</span>
											<span class="tech-tag cloud">AWS S3</span>
											<span class="tech-tag data-eng">Python</span>
										</div>
										<p>Pipeline de dados completo voltado para engenharia de dados, com ingestão automatizada de informações públicas de todos os deputados federais. 
											Os dados incluem biografia, mandatos, despesas e atividade parlamentar, extraídos via API oficial. 
											A arquitetura implementa uma abordagem moderna de ELT com <strong>Snowflake e dbt</strong>. 
											A ingestão incremental diária é orquestrada com <strong>Airflow</strong> e armazenada no S3 em formato Parquet. 
											Transformações seguem padrões robustos de modelagem dimensional (SCD Type 2). 
											O projeto garante escalabilidade, automação e qualidade de dados ponta a ponta.<p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Python, Pandas e requests</li>
														<li>Apache Airflow</li>
														<li>Amazon S3 e SQS</li>
														<li>Snowflake, Snowpipe</li>
														<li>dbt Core</li>
														<li>Streamlit e Jupyter notebook</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfe/pipeline-deputados" class="button">Saiba mais</a></li>
														<li><a href="https://medium.com/@heitorfelix/building-a-modern-data-warehouse-a-practical-guide-to-dbt-data-modeling-with-real-world-examples-1a0071b15c72" class="button">Ler artigo</a></li>

													</ul>
												</div>
											</div>
									</article>
									<article>
										<a href="https://github.com/heitorfelix/olist-pipeline" class="image"><img src="images/olist.png" alt="Diagrama do projeto olist" /></a>
										<h3>Data Lakehouse: Olist</h3>
										<div class="tech-tags">
											<span class="tech-tag data-eng">Databricks</span>
											<span class="tech-tag data-eng">Delta Lake</span>
											<span class="tech-tag data-eng">Spark</span>
											<span class="tech-tag cloud">Azure</span>
										</div>
										<p>Este projeto utilizou a arquitetura de <strong>Data Lakehouse no Databricks</strong> para gerenciar dados em camadas (Raw, Bronze, Silver e Gold) e simular cenários de ingestão com CDC (Change Data Capture). Os dados, oriundos de um dataset do Kaggle, foram enriquecidos para criar um pipeline completo, desde ingestão até análise de negócios.

											Implementei governança de dados com Unity Catalog, orquestração com Databricks Workflows, e integração contínua via GitHub Actions. O projeto consolidou habilidades em pipelines de dados, automação e análise com a arquitetura Medallion, otimizando o uso de dados para insights e aplicações analíticas. <p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Pandas</li>
														<li>Git, GitHub, GitHub Actions</li>
														<li>Azure Blob Storage, Parquet</li>
														<li>Databricks, UnityCatalog</li>
														<li>Spark, Delta Lake</li>
														<li>Databricks Workflows</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfelix/olist-pipeline" class="button">Saiba mais</a></li>
													</ul>
												</div>
											</div>
									</article>


									<article>
										<a href="https://github.com/heitorfe/RAG-llm-chatbot" class="image"><img src="images/rag.png" alt="Diagrama do projeto de OCR" /></a>
										<h3>Chatbot com GPT-4 e Azure</h3>
										<div class="tech-tags">
											<span class="tech-tag ml-ai">GPT-4</span>
											<span class="tech-tag ml-ai">RAG</span>
											<span class="tech-tag cloud">Azure OpenAI</span>
											<span class="tech-tag cloud">Azure AI Search</span>
										</div>
										<p>Neste projeto, explorei ferramentas de Inteligência Artificial do Azure para construir um chatbot especializado em Azure utilizando o GPT-4. Copiei os dados da documentação do Azure no GitHub para o Storage Account, utilizei o Azure AI Search para fazer embedding e indexação do conteúdo, e o Azure OpenAI para construção do chatbot em um App no Azure. O objetivo é fornecer respostas precisas e contextualizadas sobre serviços e funcionalidades do Azure.<p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Python</li>
														<li>Azure Blob Storage</li>
														<li>Azure AI Search</li>
														<li>Azure OpenAI</li>
														<li>Git, GitHub</li>
														<li>Bicep template (IaC)</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfe/RAG-llm-chatbot" class="button">Saiba mais</a></li>
													</ul>
												</div>
											</div>
									</article>


								</div>
							</section>







							<!-- Section -->
							<section>
								<header class="major">
									<h1>Projetos Antigos (2021 - 2022)</h1>
								</header>
								<div class="posts">
									<article>
										<a href="https://github.com/heitorfe/data_challenge_stone/" class="image"><img src="images/datachallenge.png" alt="" /></a>
										<h3>Data Challenge Stone 2022</h3>
										<div class="tech-tags">
											<span class="tech-tag data-eng">Python</span>
											<span class="tech-tag viz">Power BI</span>
											<span class="tech-tag data-eng">Pandas</span>
										</div>
										<p>Fui semifinalista no Data Challenge Stone 2022. Nesse desafio da Stone, minha tarefa foi utilizar dados históricos de um programa de empréstimos desde 2019 até abril de 2022 de 14,7 mil clientes. O problema de negócio era relacionado ao acionamento dos clientes que estavam com pagamento atrasado. A pergunta a ser respondida foi: Qual a curva ideal de vezes que devemos acionar um cliente? Para respondê-la utilizei Python e Power BI para responder a pergunta com a análise de dados. <p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Git, GitHub, LSF Git files</li>
														<li>Python, Pandas, Seaborn, Plotly</li>
														<li>Power BI</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfe/data_challenge_stone/" class="button">Saiba mais</a></li>
														<li><a href="https://app.powerbi.com/view?r=eyJrIjoiYTA4MmMyYTYtNTA2NC00ODAxLTljZjctYzUwYWE3ZmE2MDgwIiwidCI6Ijg3MDk0MzhmLTMzNDItNGI0Yy1hZDY5LTNkMjFlMmY4OTZlOSJ9" class="button">Dashboard</a></li>
													</ul>
												</div>
											</div>
									</article>

									<article>
										<a href="https://github.com/heitorfe/rossman-sales-predict" class="image"><img src="images/sales.jpg" alt="" /></a>
										<h3>Previsão de vendas</h3>
										<div class="tech-tags">
											<span class="tech-tag ml-ai">Scikit-Learn</span>
											<span class="tech-tag data-eng">Python</span>
											<span class="tech-tag cloud">Heroku</span>
											<span class="tech-tag data-eng">Flask</span>
										</div>
										<p>Usei Python para fazer um modelo de Machine Learning para prever as vendas de cada loja, das 3 mil cadastradas, nas próximas 6 semanas. O modelo foi colocado em produção e pode ser requisitado via API pelo Telegram, bastando apenas ter acesso à internet para utilizá-lo. O modelo teve previsão de 90% do valor real, possibilitando o CFO de tomar decisões baseadas no faturamento futuro de cada unidade da loja e assim, poder fazer investimentos sem prejuízos.</p>
										<!-- Lists -->
										<div class="row">
											<div class="col-6 col-12-small">
												<h4>Ferramentas utilizadas</h4>
												<ul>
													<li>Git, GitHub</li>
													<li>Python, Pandas, Seaborn, Boruta</li>
													<li>Scikit-Learn e Scipy</li>
													<li>Flask</li>
													<li>Heroku Cloud</li>
													<li>Telegram API</li>
												</ul>
												<ul class="actions">
													<li><a href="https://github.com/heitorfe/rossman-sales-predict" class="button">Saiba mais</a></li>
												</ul>
											</div>
										</div>
									</article>

									<article>
										<a href="https://github.com/heitorfe/health_insurance_cross_sale" class="image"><img src="images/cross-sell.jpg" alt="" /></a>
										<h3>Classificação de clientes mais propensos a compra</h3>
										<div class="tech-tags">
											<span class="tech-tag ml-ai">Classification</span>
											<span class="tech-tag data-eng">Python</span>
											<span class="tech-tag cloud">Heroku</span>
											<span class="tech-tag data-eng">Flask</span>
										</div>
										<p>Usei Python para fazer um modelo de Machine Learning para fazer o ranqueamento dos clientes mais propensos a adquirir um novo produto (estratégia de cross sell). Com uma precisão de 33,5% para os 20.000 primeiros clientes da base, o time comercial é capaz de atingir os interessados com muito menos custo.<p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Git, GitHub</li>
														<li>Python, Pandas, Seaborn, Extra Tree Classifier</li>
														<li>Scikit-Learn, Scipy e Scikit-Plot</li>
														<li>Flask</li>
														<li>Heroku Cloud</li>
														<li>Google Sheets API com Google Scripts</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfe/health_insurance_cross_sale" class="button">Saiba mais</a></li>
													</ul>
												</div>
											</div>
									</article>

									<article>
										<a href="https://github.com/heitorfe/insiders_clustering" class="image"><img src="images/cluster.jpg" alt="" /></a>
										<h3>Fidelização de clientes com clusterização</h3>
										<div class="tech-tags">
											<span class="tech-tag ml-ai">Clustering</span>
											<span class="tech-tag data-eng">Python</span>
											<span class="tech-tag viz">Metabase</span>
										</div>
										<p>Usei Python para fazer um modelo de Machine Learning para encontrar os "Insiders", os melhores clientes da empresa. O objetivo desse projeto foi agrupar clientes com comportamentos parecidos para o time de negócios conseguir construir ações personalizada, baseadas nas características de cada cluster. <p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Git, GitHub</li>
														<li>Python, Pandas, Seaborn, GMM</li>
														<li>Scikit-Learn, Scipy e Yellowbrick</li>
														<li>SQLite</li>
														<li>Metabase</li>
														<li>Papermill</li>
													</ul>
													<ul class="actions"></ul>
														<li><a href="https://github.com/heitorfe/insiders_clustering" class="button">Saiba mais</a></li>
													</ul>
												</div>
											</div>
									</article>

									<article>
										<a href="https://github.com/heitorfe/kc-house-insights" class="image"><img src="images/designkc.png" alt="" /></a>
										<h3>Análise de dados House Rocket</h3>
										<div class="tech-tags">
											<span class="tech-tag data-eng">Python</span>
											<span class="tech-tag viz">Power BI</span>
											<span class="tech-tag viz">Plotly</span>
										</div>
										<p>Eu usei Python e Power BI para fazer uma análise exploratória de dados e com isso confirmei ou não algumas hipóteses sobre o negócio, tendo como resultado insights para melhor performance do negócio. A análise teve como objetivo aumentar a receita da empresa fictícia, House Rocket, que funciona com a compra e venda de imóveis, encontrando os melhores momentos para se comprar ou vender o imóvel. <p>

											<!-- Lists -->
											<div class="row">
												<div class="col-6 col-12-small">
													<h4>Ferramentas utilizadas</h4>
													<ul>
														<li>Git, GitHub</li>
														<li>Python, Pandas, Seaborn, Plotly</li>
														<li>Geopy API</li>
														<li>Power BI</li>
														<li>SQLite</li>
													</ul>
													<ul class="actions">
														<li><a href="https://github.com/heitorfe/kc-house-insights" class="button">Saiba mais</a></li>
														<li><a href="https://app.powerbi.com/view?r=eyJrIjoiNzExYzgyMDQtZjU5ZC00YzAzLTk4MzItYTI3MGQ2ZDM5MDJhIiwidCI6Ijg3MDk0MzhmLTMzNDItNGI0Yy1hZDY5LTNkMjFlMmY4OTZlOSJ9&pageName=ReportSection25f6ac0f4d2653587e84" class="button">Dashboard</a></li>
													</ul>
												</div>
											</div>
									</article>
								</div>
							</section>

								<!-- Contato (loaded from shared/contact.html) -->
							<div id="contact-placeholder"></div>

						</div>
					</div>


			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/theme-toggle.js"></script>
			<script src="assets/js/carousel.js"></script>
			<script src="assets/js/shared-loader.js"></script>

	</body>
</html>
